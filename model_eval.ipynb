{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "# from torchtext.data import Field, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from scripts import *\n",
    "from Seq2seq import *\n",
    "\n",
    "file_path_alignments = './gec-datasets/alignments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_index = None\n",
    "with open(\"./pickle_files/target2index.pkl\", 'rb') as file:\n",
    "    target_to_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_to_index = None\n",
    "with open(\"./pickle_files/source2index.pkl\", 'rb') as file:\n",
    "    source_to_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word_target = None\n",
    "with open(\"./pickle_files/index2word_target.pkl\", 'rb') as file:\n",
    "    index_to_word_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, source, target,source_pad_index = source_to_index['<PAD>'],target_pad_index = target_to_index['<PAD>']):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.max_length = max(max(len(s) for s in source), max(len(t) for t in target))\n",
    "\n",
    "        self.source = torch.tensor([s + [source_pad_index] * (self.max_length - len(s)) for s in source])\n",
    "        self.target = torch.tensor([t + [target_pad_index] * (self.max_length - len(t)) for t in target])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load('./models/model.pickle', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): EncoderLSTM(\n",
      "    (embedding): Embedding(141069, 256)\n",
      "    (lstm): LSTM(256, 1024, num_layers=2, dropout=0.5)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): DecoderLSTM(\n",
      "    (embedding): Embedding(111469, 256)\n",
      "    (lstm): LSTM(256, 1024, num_layers=2, dropout=0.5)\n",
      "    (out): Linear(in_features=1024, out_features=111469, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(sentence,model):\n",
    "    model.eval()\n",
    "    lis = [source_to_index.get(word,source_to_index['<UNK>']) for word in sentence]\n",
    "    tensor = torch.tensor(lis, dtype=torch.long)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    tensor = tensor.to(device)\n",
    "    output = model.inference(tensor,tensor.shape[0])\n",
    "    output = output.reshape(-1, output.shape[2])\n",
    "    output = output.argmax(dim=1)\n",
    "    final = []\n",
    "    for indx in output:\n",
    "        final.append(index_to_word_target[indx.item()])\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,test_dataset,batch_size):\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # GPU Configuration\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    total_acc_eval = 0\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for source, targets in tqdm(test_dataloader):\n",
    "            source = source.transpose(0,1)\n",
    "            targets = targets.transpose(0,1)\n",
    "            # Move the test input to the device\n",
    "            source = source.to(device)\n",
    "            # Move the test label to the device\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Perform the forward pass\n",
    "            output = model.inference(source,source.shape[0])\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2]) \n",
    "          \n",
    "            targets = targets[1:].reshape(-1) \n",
    "\n",
    "            predictions = output.argmax(dim=1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy()) \n",
    "\n",
    "            # print(\"shape of argmax \", output.argmax(dim=1).shape)\n",
    "            acc = (output.argmax(dim=1) == targets).sum().item()\n",
    "            total_acc_eval += acc\n",
    "     \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted', zero_division = 0)\n",
    "    acc = total_acc_eval / (len(test_dataset) * len(test_dataset[0][0]))\n",
    "    print(f'Evaluation Accuracy: {acc}  Precision: {precision}  Recall: {recall}  F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'المظلم', 'فهو', 'تعلم', 'أشياء', 'خاطئة', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "test =  ['<SOS>', 'المضلم', 'فهوا', 'تعلم', 'أشياء', 'خاطئة', '<EOS>']\n",
    "output = predict(test,model)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4627, 33766, 2316, 159, 18976, 1] [0, 4322, 29196, 2196, 163, 16878, 1]\n"
     ]
    }
   ],
   "source": [
    "test_source, test_targets = read_alignments(file_path_alignments + 'zaebuc/zaebuc_dev.txt')\n",
    "test_source, test_targets = create_windows(test_source, test_targets, window_size = 5)\n",
    "test_source = convert_to_indicies(test_source, source_to_index)\n",
    "test_targets = convert_to_indicies(test_targets, target_to_index)\n",
    "print(test_source[-5],test_targets[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(test_source, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:05<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.6533980582524271  Precision: 0.7870174940650821  Recall: 0.7622977346278317  F1 Score: 0.766382658802384\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,test_dataset,64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
