{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8494732,"sourceType":"datasetVersion","datasetId":5068592},{"sourceId":8494773,"sourceType":"datasetVersion","datasetId":5068624}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyarabic\n# !pip install keras_preprocessing","metadata":{"executionInfo":{"elapsed":24332,"status":"ok","timestamp":1716371351468,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"},"user_tz":-180},"id":"Z6Sc0yodRUIh","outputId":"3f9db776-beb5-40cf-bb77-c5e24f301d1f","execution":{"iopub.status.busy":"2024-05-25T08:34:08.418932Z","iopub.execute_input":"2024-05-25T08:34:08.419956Z","iopub.status.idle":"2024-05-25T08:34:20.590461Z","shell.execute_reply.started":"2024-05-25T08:34:08.419904Z","shell.execute_reply":"2024-05-25T08:34:20.589490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# import os\n# import sys\n\n# drive.mount('/content/drive')\n# sys.path.append('/content/drive/MyDrive/Grammer_Correction/')\n\n# os.chdir('/content/drive/MyDrive/Grammer_Correction/')","metadata":{"executionInfo":{"elapsed":20512,"status":"ok","timestamp":1716371387088,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"},"user_tz":-180},"id":"qo17735lS2d6","outputId":"570f5e40-3ae8-466a-a872-93edd833830f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom enum import Enum\nimport re\nimport numpy as np\nfrom pyarabic.araby import separate, tokenize, is_arabicrange, strip_tashkeel, strip_tatweel\n# import tensorflow as tf\n# from keras_preprocessing.sequence import pad_sequences\n# from keras.models import Sequential,load_model, Model\n# from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, CategoryEncoding, Bidirectional, Input, Concatenate, Dropout, TimeDistributed, RepeatVector, Flatten\n# from keras.initializers import glorot_normal\n# from keras.losses import SparseCategoricalCrossentropy, CategoricalFocalCrossentropy\n# from keras.metrics import SparseCategoricalAccuracy, F1Score\n# from keras.utils import plot_model,to_categorical\nfrom gensim.models import Word2Vec, FastText,KeyedVectors\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n# from torchtext.data import Field, BucketIterator\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\nfile_path_alignments = \"/kaggle/input/arabic-gec-datasets/datasets/alignments/\"\nfile_path_datasets = \"/kaggle/input/arabic-gec-datasets/datasets/ged_datasets/\"\n\n# from scripts_ged.ged_scripts.ged_preprocessor import *","metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1716372077531,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"},"user_tz":-180},"id":"NAnB4nQaTTZr","execution":{"iopub.status.busy":"2024-05-25T08:34:38.115390Z","iopub.execute_input":"2024-05-25T08:34:38.116044Z","iopub.status.idle":"2024-05-25T08:34:38.124091Z","shell.execute_reply.started":"2024-05-25T08:34:38.116011Z","shell.execute_reply":"2024-05-25T08:34:38.123168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:34:40.850639Z","iopub.execute_input":"2024-05-25T08:34:40.851457Z","iopub.status.idle":"2024-05-25T08:34:40.909153Z","shell.execute_reply.started":"2024-05-25T08:34:40.851424Z","shell.execute_reply":"2024-05-25T08:34:40.908091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_arabic_for_word2vec(input_filepath):\n    all_sentences = []\n    arabic_list = []\n    with open(input_filepath, 'r', encoding='utf-8') as input_file:\n        for line in input_file:\n            if line.strip() == \".\":\n              arabic_list.append(line.strip())\n              all_sentences.append(arabic_list)\n              arabic_list = []\n            else:\n              arabic_list.append(line.strip())\n    return all_sentences\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:34:41.231498Z","iopub.execute_input":"2024-05-25T08:34:41.232068Z","iopub.status.idle":"2024-05-25T08:34:41.237767Z","shell.execute_reply.started":"2024-05-25T08:34:41.232035Z","shell.execute_reply":"2024-05-25T08:34:41.236875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_alignments(input_file_name):\n  space_token = '<SPACE>'\n  source_list = []\n  target_list = []\n\n  with open(input_file_name, 'r', encoding='utf-8') as file:\n      count = 1  # Initialize count to 0 to correctly skip the header\n      for line in file:\n          string = line\n          line = line.split('\\t')\n          if count == 1:  # Skip the first line (header)\n              count += 1\n              continue\n          if len(line) == 2:\n            if line[1].strip() == '':\n              source_list.append(line[0].strip())\n              target_list.append(space_token)\n            # print(line)\n            elif string.startswith('\\t'):\n              # print(string)\n              # print(line)\n              # print(line)\n              source_list.append(space_token)\n              target_list.append(line[1].strip())\n            else:\n              # print(string)\n              # print(line)\n              source_list.append(line[0].strip())\n              target_list.append(line[1].strip())\n          # print(source_list)\n          count+=1\n          # print(count)\n\n  return source_list, target_list\n","metadata":{"id":"pjXw5FVXUVBq","executionInfo":{"status":"ok","timestamp":1716371421314,"user_tz":-180,"elapsed":280,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:34:41.729553Z","iopub.execute_input":"2024-05-25T08:34:41.729931Z","iopub.status.idle":"2024-05-25T08:34:41.739480Z","shell.execute_reply.started":"2024-05-25T08:34:41.729901Z","shell.execute_reply":"2024-05-25T08:34:41.738017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_windows(source_list,target_list,window_size):\n  source_windows = []\n  target_windows = []\n  assert len(source_list) == len(target_list)\n  for i in range(0,len(source_list),window_size):\n    source_window = source_list[i:i+window_size] if i+window_size <= len(source_list) else source_list[i:]\n    target_window = target_list[i:i+window_size] if i+window_size <= len(target_list) else target_list[i:]\n    source_windows.append(['<SOS>'] + source_window + ['<EOS>'])\n    target_windows.append(['<SOS>'] + target_window + ['<EOS>'])\n  return source_windows, target_windows\n","metadata":{"id":"Y97ZzpTWvWdY","executionInfo":{"status":"ok","timestamp":1716371423990,"user_tz":-180,"elapsed":264,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:34:42.189791Z","iopub.execute_input":"2024-05-25T08:34:42.190199Z","iopub.status.idle":"2024-05-25T08:34:42.196959Z","shell.execute_reply.started":"2024-05-25T08:34:42.190168Z","shell.execute_reply":"2024-05-25T08:34:42.195961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_indicies(source_list, word_to_index):\n  source_indicies = []\n  for source in source_list:\n    source_indicies.append([word_to_index.get(word,word_to_index['<UNK>']) for word in source])\n  return source_indicies\n","metadata":{"id":"ElZ4Eaob0-Lw","executionInfo":{"status":"ok","timestamp":1716371433648,"user_tz":-180,"elapsed":331,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:34:42.553515Z","iopub.execute_input":"2024-05-25T08:34:42.554305Z","iopub.status.idle":"2024-05-25T08:34:42.558943Z","shell.execute_reply.started":"2024-05-25T08:34:42.554273Z","shell.execute_reply":"2024-05-25T08:34:42.558025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_word_to_index(token_lists):\n    # Initialize the dictionary with special tokens\n    word_to_index = {'<SOS>': 0, '<EOS>': 1}\n    \n    # Start the index from 2 since 0 and 1 are already used\n    index = 2\n    \n    # Iterate through the list of lists\n    for token_list in token_lists:\n        for token in token_list:\n            # Add the token to the dictionary if it's not already present\n            if token not in word_to_index:\n                word_to_index[token] = index\n                index += 1\n                \n    if '<UNK>' not in word_to_index:\n        word_to_index['<UNK>'] = index\n        index+=1\n    if '<PAD>' not in word_to_index:\n        word_to_index['<PAD>'] =index\n        index+=1\n        \n    return word_to_index","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:34:42.904902Z","iopub.execute_input":"2024-05-25T08:34:42.905248Z","iopub.status.idle":"2024-05-25T08:34:42.911790Z","shell.execute_reply.started":"2024-05-25T08:34:42.905222Z","shell.execute_reply":"2024-05-25T08:34:42.910736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nsource_list1, target_list1 = read_alignments(file_path_alignments + 'qalb14/qalb14_train.txt')\nsource_list1, target_list1 = create_windows(source_list1,target_list1,window_size = 5)\nprint(len(source_list1))\n\nsource_list2, target_list2 = read_alignments(file_path_alignments + 'qalb15/qalb15_train.txt')\nsource_list2, target_list2 = create_windows(source_list2,target_list2,window_size = 5)\nprint(len(source_list2))\n\nsource_list3, target_list3 = read_alignments(file_path_alignments + 'zaebuc/zaebuc_train.txt')\nsource_list3, target_list3 = create_windows(source_list3,target_list3,window_size = 5)\nprint(len(source_list3))\n\nsource_list = []\ntarget_list = []\n\nsource_list += (source_list1 + source_list2 + source_list3)\n\ntarget_list += (target_list1 + target_list2 + target_list3)\n\ndel source_list1 , source_list2, source_list3, target_list1, target_list2, target_list3\ngc.collect()\nprint(len(source_list))\n\n\n","metadata":{"id":"QrlIGHBHJxCD","executionInfo":{"status":"ok","timestamp":1716371487371,"user_tz":-180,"elapsed":3574,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:34:43.304330Z","iopub.execute_input":"2024-05-25T08:34:43.304706Z","iopub.status.idle":"2024-05-25T08:34:47.040447Z","shell.execute_reply.started":"2024-05-25T08:34:43.304675Z","shell.execute_reply":"2024-05-25T08:34:47.039428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open('output.txt','w') as f:\n#     for i,j in zip(source_list, target_list):\n#         f.write(i + '\\t' + j + '\\n')\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:34:47.042069Z","iopub.execute_input":"2024-05-25T08:34:47.042377Z","iopub.status.idle":"2024-05-25T08:34:47.046755Z","shell.execute_reply.started":"2024-05-25T08:34:47.042351Z","shell.execute_reply":"2024-05-25T08:34:47.045667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(source_list[-7])\nprint(target_list[-7])\nprint(len(target_list))","metadata":{"id":"xIcAhwvYxZrJ","executionInfo":{"status":"ok","timestamp":1716357230965,"user_tz":-180,"elapsed":359,"user":{"displayName":"Hossam Nabil","userId":"15773122680535247840"}},"outputId":"61323e16-d218-40f9-c29f-d24ae0174ebe","execution":{"iopub.status.busy":"2024-05-25T08:34:47.047767Z","iopub.execute_input":"2024-05-25T08:34:47.048099Z","iopub.status.idle":"2024-05-25T08:34:47.056993Z","shell.execute_reply.started":"2024-05-25T08:34:47.048074Z","shell.execute_reply":"2024-05-25T08:34:47.056111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word2vec Finetuning","metadata":{"id":"aiqdfOPGTmAo"}},{"cell_type":"code","source":"arabic_list = read_arabic_for_word2vec(file_path_datasets + \"splitted_qalb14/train.txt\")\narabic_list2 = read_arabic_for_word2vec(file_path_datasets + \"splitted_qalb15/qalb15_train.txt\")\narabic_list3 = read_arabic_for_word2vec(file_path_datasets + \"splitted_zaebuc/zaebuc_train.txt\")\narabic_list4 = read_arabic_for_word2vec(file_path_datasets  + \"splitted_qalb14/dev.txt\")\narabic_list5 = read_arabic_for_word2vec(file_path_datasets  + \"splitted_qalb14/test.txt\")\narabic_list6 = read_arabic_for_word2vec(file_path_datasets  + \"splitted_zaebuc/dev_train.txt\")\narabic_list.extend(arabic_list2)\narabic_list.extend(arabic_list3)\narabic_list.extend(arabic_list4)\narabic_list.extend(arabic_list5)\narabic_list.extend(arabic_list6)\n# add <SOS> and <EOS> tokens at beginning and end of each sentence in arabic_list where each sentence is a list of tokens\nfor i in range(len(arabic_list)):\n  arabic_list[i] = ['<SOS>'] + arabic_list[i] + ['<EOS>']\n\narabic_list.extend(target_list)\n\n\nword2vec_model = Word2Vec(sentences=arabic_list, vector_size=256, window=5, min_count=0, workers=4, sg=1)","metadata":{"executionInfo":{"elapsed":94201,"status":"ok","timestamp":1716371584627,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"},"user_tz":-180},"id":"lDPTd26_TrMh","execution":{"iopub.status.busy":"2024-05-25T08:34:55.091469Z","iopub.execute_input":"2024-05-25T08:34:55.091859Z","iopub.status.idle":"2024-05-25T08:35:42.428910Z","shell.execute_reply.started":"2024-05-25T08:34:55.091797Z","shell.execute_reply":"2024-05-25T08:35:42.428092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(arabic_list[0])","metadata":{"id":"Jo9vrRml24Fj","executionInfo":{"status":"ok","timestamp":1716308965705,"user_tz":-180,"elapsed":279,"user":{"displayName":"Hossam Nabil","userId":"15773122680535247840"}},"outputId":"f1cf53ee-3fb9-4a45-9cf4-5acde28a955b","execution":{"iopub.status.busy":"2024-05-25T08:35:42.430951Z","iopub.execute_input":"2024-05-25T08:35:42.431371Z","iopub.status.idle":"2024-05-25T08:35:42.436286Z","shell.execute_reply.started":"2024-05-25T08:35:42.431337Z","shell.execute_reply":"2024-05-25T08:35:42.435397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Glove model vectors\n","metadata":{"id":"hN9Lv_e7z-Rt"}},{"cell_type":"code","source":"# load glove model\n# glove_model = KeyedVectors.load('./models/glove_word2vec_model.kv')\n","metadata":{"id":"N_WpudcXTs01","executionInfo":{"status":"ok","timestamp":1716371604614,"user_tz":-180,"elapsed":15534,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:35:42.437287Z","iopub.execute_input":"2024-05-25T08:35:42.437647Z","iopub.status.idle":"2024-05-25T08:35:42.444731Z","shell.execute_reply.started":"2024-05-25T08:35:42.437595Z","shell.execute_reply":"2024-05-25T08:35:42.443882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Embedding matrix creation\n","metadata":{"id":"ry-TQ9x50KMr"}},{"cell_type":"code","source":"all_tokens = source_list + target_list\nword_to_index = create_word_to_index(all_tokens)\nindex_to_word = {idx: word for word, idx in word_to_index.items()}\nvocab_size = len(word_to_index)\nprint(vocab_size)\nword_to_index['المظلم']","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:42.447110Z","iopub.execute_input":"2024-05-25T08:35:42.447653Z","iopub.status.idle":"2024-05-25T08:35:43.025532Z","shell.execute_reply.started":"2024-05-25T08:35:42.447603Z","shell.execute_reply":"2024-05-25T08:35:43.024601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_vocab = set(word_to_index.keys())\nprint(len(combined_vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.026656Z","iopub.execute_input":"2024-05-25T08:35:43.026966Z","iopub.status.idle":"2024-05-25T08:35:43.059999Z","shell.execute_reply.started":"2024-05-25T08:35:43.026941Z","shell.execute_reply":"2024-05-25T08:35:43.059095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_to_index = create_word_to_index(source_list)\nprint(len(source_to_index))\nsource_vocab_size = len(source_to_index)\nprint(source_to_index['المضلم'])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.061211Z","iopub.execute_input":"2024-05-25T08:35:43.061521Z","iopub.status.idle":"2024-05-25T08:35:43.322698Z","shell.execute_reply.started":"2024-05-25T08:35:43.061497Z","shell.execute_reply":"2024-05-25T08:35:43.321717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_to_index = create_word_to_index(target_list)\nprint(len(target_to_index))\ntarget_vocab_size = len(target_to_index)\nprint(target_to_index['المظلم'])\nindex_to_word_target = {idx: word for word, idx in target_to_index.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.323905Z","iopub.execute_input":"2024-05-25T08:35:43.324214Z","iopub.status.idle":"2024-05-25T08:35:43.603691Z","shell.execute_reply.started":"2024-05-25T08:35:43.324187Z","shell.execute_reply":"2024-05-25T08:35:43.602774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec_vocab = set(word2vec_model.wv.key_to_index.keys())\n# # glove_vocab = set(glove_model.key_to_index.keys())\n# combined_vocab = word2vec_vocab.copy() # .union(glove_vocab)\n# # print(len(glove_vocab))\n# print(len(word2vec_vocab))\n# print(len(combined_vocab))\n# combined_vocab.add('<UNK>')\n# combined_vocab.add('<SPACE>')\n# combined_vocab.add('<PAD>')\n# print(len(combined_vocab))","metadata":{"id":"LdhSYD-F0LiK","executionInfo":{"status":"ok","timestamp":1716371607542,"user_tz":-180,"elapsed":895,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"outputId":"bb50913e-adc9-483c-dc79-757a273a4563","execution":{"iopub.status.busy":"2024-05-25T08:35:43.604792Z","iopub.execute_input":"2024-05-25T08:35:43.605114Z","iopub.status.idle":"2024-05-25T08:35:43.633338Z","shell.execute_reply.started":"2024-05-25T08:35:43.605089Z","shell.execute_reply":"2024-05-25T08:35:43.632007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word_to_index = {word: idx for idx, word in enumerate(combined_vocab)}\n# index_to_word = {idx: word for word, idx in word_to_index.items()}\n# index = word_to_index[\"<UNK>\"]\n# index_to_word[index]\n# vocab_size = len(combined_vocab)","metadata":{"id":"CsJfjbnF0JZf","executionInfo":{"status":"ok","timestamp":1716371614803,"user_tz":-180,"elapsed":281,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:35:43.634466Z","iopub.execute_input":"2024-05-25T08:35:43.634738Z","iopub.status.idle":"2024-05-25T08:35:43.645543Z","shell.execute_reply.started":"2024-05-25T08:35:43.634714Z","shell.execute_reply":"2024-05-25T08:35:43.644606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open('source2index.pkl', 'wb') as file:\n    # Serialize the dictionary and write it to the file\n    pickle.dump(source_to_index, file)\n    \nwith open('target2index.pkl', 'wb') as file:\n    # Serialize the dictionary and write it to the file\n    pickle.dump(target_to_index, file)\n\n    \nwith open('index2word_target.pkl', 'wb') as file:\n    # Serialize the dictionary and write it to the file\n    pickle.dump(index_to_word_target, file)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.648783Z","iopub.execute_input":"2024-05-25T08:35:43.649188Z","iopub.status.idle":"2024-05-25T08:35:43.769882Z","shell.execute_reply.started":"2024-05-25T08:35:43.649163Z","shell.execute_reply":"2024-05-25T08:35:43.768867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_vocab = set(source_to_index.keys())\nprint(len(source_vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.771131Z","iopub.execute_input":"2024-05-25T08:35:43.771436Z","iopub.status.idle":"2024-05-25T08:35:43.793545Z","shell.execute_reply.started":"2024-05-25T08:35:43.771412Z","shell.execute_reply":"2024-05-25T08:35:43.792574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_vocab = set(target_to_index.keys())\nprint(len(target_vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.794833Z","iopub.execute_input":"2024-05-25T08:35:43.795174Z","iopub.status.idle":"2024-05-25T08:35:43.819429Z","shell.execute_reply.started":"2024-05-25T08:35:43.795143Z","shell.execute_reply":"2024-05-25T08:35:43.818150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_embedding_matrix(vocab, vocab_size, embedding_dim, word_to_index, word2vec_model,word2vec_vocab):\n    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n    unk = 0\n    mean = np.mean(word2vec_model.wv.vectors, axis=0)\n    for word in vocab:\n        # if word in glove_vocab:\n        #     embedding_matrix[word_to_index[word]] = glove_model[word]\n        if word == '<SPACE>':\n            embedding_matrix[word_to_index[word]] = np.zeros(embedding_dim)\n        elif word == '<PAD>':\n            embedding_matrix[word_to_index[word]] = np.ones(embedding_dim)\n        elif word in word2vec_vocab:\n            embedding_matrix[word_to_index[word]] = word2vec_model.wv[word]\n        else:\n            # <UNK> token\n                unk+=1\n                embedding_matrix[word_to_index[word]] = mean\n\n    print(unk)\n    return embedding_matrix\n        ","metadata":{"id":"PFI4Fjwc_SED","executionInfo":{"status":"ok","timestamp":1716371645549,"user_tz":-180,"elapsed":976,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:35:43.820685Z","iopub.execute_input":"2024-05-25T08:35:43.820993Z","iopub.status.idle":"2024-05-25T08:35:43.881059Z","shell.execute_reply.started":"2024-05-25T08:35:43.820968Z","shell.execute_reply":"2024-05-25T08:35:43.880101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_embedding_matrix = create_embedding_matrix(source_vocab,source_vocab_size, 256, source_to_index, word2vec_model, word2vec_vocab)\ntarget_embedding_matrix = create_embedding_matrix(target_vocab,target_vocab_size, 256, target_to_index, word2vec_model, word2vec_vocab)\nembedding_matrix = create_embedding_matrix(combined_vocab,vocab_size, 256, word_to_index, word2vec_model, word2vec_vocab)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:43.882449Z","iopub.execute_input":"2024-05-25T08:35:43.882751Z","iopub.status.idle":"2024-05-25T08:35:46.146446Z","shell.execute_reply.started":"2024-05-25T08:35:43.882719Z","shell.execute_reply":"2024-05-25T08:35:46.145464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:46.147655Z","iopub.execute_input":"2024-05-25T08:35:46.148298Z","iopub.status.idle":"2024-05-25T08:35:46.154261Z","shell.execute_reply.started":"2024-05-25T08:35:46.148261Z","shell.execute_reply":"2024-05-25T08:35:46.153317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:46.155295Z","iopub.execute_input":"2024-05-25T08:35:46.155533Z","iopub.status.idle":"2024-05-25T08:35:46.163428Z","shell.execute_reply.started":"2024-05-25T08:35:46.155512Z","shell.execute_reply":"2024-05-25T08:35:46.162606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:35:46.164631Z","iopub.execute_input":"2024-05-25T08:35:46.164985Z","iopub.status.idle":"2024-05-25T08:35:46.172988Z","shell.execute_reply.started":"2024-05-25T08:35:46.164960Z","shell.execute_reply":"2024-05-25T08:35:46.172106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Definition\n","metadata":{"id":"_dMCJZqjDdDR"}},{"cell_type":"code","source":"class EncoderLSTM(nn.Module):\n\n  def __init__(self,input_size, embedding_dim, embedding_matrix , hidden_size, num_layers, dropout_p=0.1):\n    super(EncoderLSTM,self).__init__()\n    self.embedding = nn.Embedding(input_size,embedding_dim)\n    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n\n#     self.embedding.weight.requires_grad = False # to prevent trainable embeddings (subject to trial)\n\n    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=dropout_p) # (number of layers, batch_size, hidden_size)\n    self.dropout = nn.Dropout(dropout_p)\n\n  def forward(self,input):\n\n     # input = [max_seq_length,batch size]\n    #  print('input to encoder shape ', input.shape)\n\n\n     embedded = self.dropout(self.embedding(input))\n     # embedded = [max_seq_length, batch size, embedding_dim]\n    #  print(\"encoder input to lstm shape\", embedded.shape)\n\n     output, (hidden, cell) = self.lstm(embedded)\n     return hidden, cell\n","metadata":{"id":"f5G3BxoADgN3","executionInfo":{"status":"ok","timestamp":1716378915817,"user_tz":-180,"elapsed":318,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:35:46.173909Z","iopub.execute_input":"2024-05-25T08:35:46.174188Z","iopub.status.idle":"2024-05-25T08:35:46.182703Z","shell.execute_reply.started":"2024-05-25T08:35:46.174166Z","shell.execute_reply":"2024-05-25T08:35:46.181836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder Definition","metadata":{"id":"k8dZxPIWtfJs"}},{"cell_type":"code","source":"\nclass DecoderLSTM(nn.Module):\n    def __init__(self, output_size,embedding_dim, embedding_matrix, hidden_size, num_layers, dropout_p=0.1):\n        super(DecoderLSTM, self).__init__()\n        self.embedding = nn.Embedding(output_size, embedding_dim)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n\n        # If you want to freeze the embedding layer (no training)\n#         self.embedding.weight.requires_grad = False\n\n        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=dropout_p) # hidden size of decoder should be the same as the encoder\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input, hidden, cell):\n        input = input.unsqueeze(0) # since input is of shape N (Batch_size)\n        # shape of input: (1,Batch_size) --> one word per batch as the decoder outputs one word at a time\n        # print(\"input to decoder shape \",input.shape)\n        output = self.dropout(self.embedding(input))\n        # shape of output: (1,Batch_size,embedding_dim)\n        # print(\"output of embedding layer shape\", output.shape)\n        # print(\"hidden input to decoder shape \", hidden.shape)\n        output, (hidden,cell) = self.lstm(output, (hidden,cell))\n        # shape of output: (1,Batch_size,hidden_size)\n        # print(\"output of lstm of decoder shape \", output.shape)\n        output = self.out(output)\n        # print(\"output of dense of decoder shape \", output.shape)\n        # shape of output: (1,Batch_size,output_size(Vocab_size))\n\n        output = output.squeeze(0)\n        # print(\"output of lstm of decoder shape after squeezing \", output.shape)\n\n        # shape of output: (Batch_size,output_size(Vocab_size))\n        return output, hidden, cell","metadata":{"id":"s9fMY6A5FZIw","executionInfo":{"status":"ok","timestamp":1716378917961,"user_tz":-180,"elapsed":292,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:35:46.185486Z","iopub.execute_input":"2024-05-25T08:35:46.186165Z","iopub.status.idle":"2024-05-25T08:35:46.194971Z","shell.execute_reply.started":"2024-05-25T08:35:46.186139Z","shell.execute_reply":"2024-05-25T08:35:46.194145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self,source,target,teacher_force_ratio = 0.5):\n\n        batch_size = source.shape[1]  # source shape (seq_len, batch_size)\n        # print(\"batch_size \",batch_size)\n        target_len = target.shape[0]    # target shape (seq_len, batch_size)\n        # print(\"target_length \",target_len)\n        target_vocab_size = self.decoder.out.out_features\n        outputs = torch.zeros(target_len,batch_size,target_vocab_size).to(device)\n        hidden, cell = self.encoder(source)\n        # print(\"encoder output shape \", hidden.shape)\n        # shape of hidden: (num_layers * num_directions, Batch_size, hidden_size)\n        # shape of cell: (num_layers * num_directions, Batch_size, hidden_size)\n        x = target[0]\n        # print(\"target[0] \",x, x.shape)\n        for t in range(1, target_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[t] = output\n            max_pred = output.argmax(1)\n            x = target[t] if random.random() < teacher_force_ratio else max_pred\n        return outputs\n    \n    def inference(self, source, max_len, start_token_id = target_to_index['<SOS>']):\n        batch_size = source.shape[1]\n        target_vocab_size = self.decoder.out.out_features\n        outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(device)\n        hidden, cell = self.encoder(source)\n\n        # Start token, assuming it's the first token in the target vocab\n        x = torch.full((batch_size,), start_token_id, dtype=torch.long).to(device)\n        \n        for t in range(1, max_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[t] = output\n            max_pred = output.argmax(1)\n            x = max_pred\n        \n        return outputs\n\n","metadata":{"id":"LVxBInuiZVY6","executionInfo":{"status":"ok","timestamp":1716378964571,"user_tz":-180,"elapsed":437,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:36:11.577589Z","iopub.execute_input":"2024-05-25T08:36:11.577991Z","iopub.status.idle":"2024-05-25T08:36:11.653583Z","shell.execute_reply.started":"2024-05-25T08:36:11.577958Z","shell.execute_reply":"2024-05-25T08:36:11.652491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preperation","metadata":{"id":"SWJPeCkmqLKo"}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, source, target,source_pad_index = source_to_index['<PAD>'],target_pad_index = target_to_index['<PAD>']):\n        self.source = source\n        self.target = target\n        self.max_length = max(max(len(s) for s in source), max(len(t) for t in target))\n\n        self.source = torch.tensor([s + [source_pad_index] * (self.max_length - len(s)) for s in source])\n        self.target = torch.tensor([t + [target_pad_index] * (self.max_length - len(t)) for t in target])\n\n    def __len__(self):\n        return len(self.source)\n\n    def __getitem__(self, idx):\n        return self.source[idx], self.target[idx]","metadata":{"id":"ZFt2GIXHzWA0","executionInfo":{"status":"ok","timestamp":1716371673458,"user_tz":-180,"elapsed":300,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:36:32.066850Z","iopub.execute_input":"2024-05-25T08:36:32.067258Z","iopub.status.idle":"2024-05-25T08:36:32.075751Z","shell.execute_reply.started":"2024-05-25T08:36:32.067225Z","shell.execute_reply":"2024-05-25T08:36:32.074655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(source_list[-1],target_list[-1])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:36:37.116704Z","iopub.execute_input":"2024-05-25T08:36:37.117580Z","iopub.status.idle":"2024-05-25T08:36:37.122209Z","shell.execute_reply.started":"2024-05-25T08:36:37.117547Z","shell.execute_reply":"2024-05-25T08:36:37.121312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(word_to_index['<PAD>'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_list = convert_to_indicies(source_list,source_to_index)\ntarget_list = convert_to_indicies(target_list,target_to_index)\n","metadata":{"id":"o12zuo41uXii","executionInfo":{"status":"ok","timestamp":1716371691622,"user_tz":-180,"elapsed":2475,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:36:45.699502Z","iopub.execute_input":"2024-05-25T08:36:45.700128Z","iopub.status.idle":"2024-05-25T08:36:47.613732Z","shell.execute_reply.started":"2024-05-25T08:36:45.700096Z","shell.execute_reply":"2024-05-25T08:36:47.612726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(source_list[-1],target_list[-1])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:36:48.566674Z","iopub.execute_input":"2024-05-25T08:36:48.567490Z","iopub.status.idle":"2024-05-25T08:36:48.572436Z","shell.execute_reply.started":"2024-05-25T08:36:48.567457Z","shell.execute_reply":"2024-05-25T08:36:48.571151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 5\nmini_sentences = source_list[0: 8]\nmini_labels = target_list[0: 8]\nmini_dataset = Dataset(mini_sentences, mini_labels)\ndummy_dataloader = torch.utils.data.DataLoader(mini_dataset, batch_size=5)\ndg = iter(dummy_dataloader)\nX1, Y1 = next(dg)\nX2, Y2 = next(dg)\nprint(Y1.shape, X1.shape, Y2.shape, X2.shape)\nprint(X1[0][:], \"\\n\", Y1[0][:])","metadata":{"id":"ROgSXyqs0lhe","executionInfo":{"status":"ok","timestamp":1716371692995,"user_tz":-180,"elapsed":282,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"outputId":"7c4f7db2-aa00-43ae-f5c8-810008e833c8","execution":{"iopub.status.busy":"2024-05-25T08:36:52.904895Z","iopub.execute_input":"2024-05-25T08:36:52.905266Z","iopub.status.idle":"2024-05-25T08:36:52.915903Z","shell.execute_reply.started":"2024-05-25T08:36:52.905236Z","shell.execute_reply":"2024-05-25T08:36:52.914775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset(source_list, target_list)","metadata":{"id":"mvNx7gkxseeE","executionInfo":{"status":"ok","timestamp":1716371701267,"user_tz":-180,"elapsed":1473,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:36:57.378315Z","iopub.execute_input":"2024-05-25T08:36:57.378708Z","iopub.status.idle":"2024-05-25T08:36:59.658631Z","shell.execute_reply.started":"2024-05-25T08:36:57.378678Z","shell.execute_reply":"2024-05-25T08:36:59.657860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Hyperparamaters","metadata":{"id":"edLLyfXxiAb_"}},{"cell_type":"code","source":"num_epochs = 10\nbatch_size = 64\nlearning_rate = 0.001","metadata":{"id":"uXLj5Ttnh-yq","executionInfo":{"status":"ok","timestamp":1716372020870,"user_tz":-180,"elapsed":279,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:37:00.484320Z","iopub.execute_input":"2024-05-25T08:37:00.484942Z","iopub.status.idle":"2024-05-25T08:37:00.489439Z","shell.execute_reply.started":"2024-05-25T08:37:00.484907Z","shell.execute_reply":"2024-05-25T08:37:00.488438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:37:02.623310Z","iopub.execute_input":"2024-05-25T08:37:02.624194Z","iopub.status.idle":"2024-05-25T08:37:02.628708Z","shell.execute_reply.started":"2024-05-25T08:37:02.624159Z","shell.execute_reply":"2024-05-25T08:37:02.627743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Hyperparamaters\n","metadata":{"id":"bsNqN_xgiGuC"}},{"cell_type":"code","source":"load_model = False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nencoder_input_size = source_vocab_size\ndecoder_input_size = target_vocab_size\nembedding_size = 256\nhidden_size = 1024\nnum_layers = 2\ndropout_p = 0.5\nprint(device)\n","metadata":{"id":"LJJRngnniJiX","executionInfo":{"status":"ok","timestamp":1716371731801,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"outputId":"b2131a8f-eeab-444f-d1f9-51564dbcb636","execution":{"iopub.status.busy":"2024-05-25T08:37:08.752987Z","iopub.execute_input":"2024-05-25T08:37:08.753969Z","iopub.status.idle":"2024-05-25T08:37:08.759412Z","shell.execute_reply.started":"2024-05-25T08:37:08.753933Z","shell.execute_reply":"2024-05-25T08:37:08.758461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hidden_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:37:12.079324Z","iopub.execute_input":"2024-05-25T08:37:12.079971Z","iopub.status.idle":"2024-05-25T08:37:12.084546Z","shell.execute_reply.started":"2024-05-25T08:37:12.079937Z","shell.execute_reply":"2024-05-25T08:37:12.083640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hidden_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:37:14.761512Z","iopub.execute_input":"2024-05-25T08:37:14.762201Z","iopub.status.idle":"2024-05-25T08:37:14.766993Z","shell.execute_reply.started":"2024-05-25T08:37:14.762167Z","shell.execute_reply":"2024-05-25T08:37:14.765980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = EncoderLSTM(\n    encoder_input_size,\n    embedding_size,\n    source_embedding_matrix,\n    hidden_size,\n    num_layers,\n    dropout_p\n).to(device)","metadata":{"id":"K8-wGnx0qOH8","executionInfo":{"status":"ok","timestamp":1716378976508,"user_tz":-180,"elapsed":1030,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:37:16.712206Z","iopub.execute_input":"2024-05-25T08:37:16.712940Z","iopub.status.idle":"2024-05-25T08:37:17.509895Z","shell.execute_reply.started":"2024-05-25T08:37:16.712908Z","shell.execute_reply":"2024-05-25T08:37:17.509075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder = DecoderLSTM(\n    decoder_input_size,\n    embedding_size,\n    target_embedding_matrix,\n    hidden_size,\n    num_layers,\n    dropout_p,\n).to(device)","metadata":{"id":"uiDR4N8PqfGA","executionInfo":{"status":"ok","timestamp":1716378978796,"user_tz":-180,"elapsed":1980,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:37:17.511447Z","iopub.execute_input":"2024-05-25T08:37:17.511745Z","iopub.status.idle":"2024-05-25T08:37:19.299252Z","shell.execute_reply.started":"2024-05-25T08:37:17.511720Z","shell.execute_reply":"2024-05-25T08:37:19.298231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Seq2Seq(encoder, decoder).to(device)\nprint(model)\n","metadata":{"id":"UNrpjCUlq1_S","executionInfo":{"status":"ok","timestamp":1716378978797,"user_tz":-180,"elapsed":5,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"outputId":"268a41e8-1170-4479-f9c4-68ec898a47d5","execution":{"iopub.status.busy":"2024-05-25T08:37:19.301286Z","iopub.execute_input":"2024-05-25T08:37:19.301664Z","iopub.status.idle":"2024-05-25T08:37:19.310008Z","shell.execute_reply.started":"2024-05-25T08:37:19.301631Z","shell.execute_reply":"2024-05-25T08:37:19.309023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{"id":"VJu8GCyh7Upd"}},{"cell_type":"code","source":"def eval_fun(training_example,model):\n    lis = [word_to_index.get(word,source_to_index['<UNK>']) for word in training_example]\n    tensor = torch.tensor(lis, dtype=torch.long)\n    tensor = tensor.unsqueeze(1)\n    tensor = tensor.to(device)\n    output = model.inference(tensor,tensor.shape[0])\n    output = output.reshape(-1, output.shape[2])\n    output = output.argmax(dim=1)\n    final = []\n    for indx in output:\n        final.append(index_to_word_target[indx.item()])\n    \n    return final\n        \n   ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:38:39.030531Z","iopub.execute_input":"2024-05-25T08:38:39.031255Z","iopub.status.idle":"2024-05-25T08:38:39.038268Z","shell.execute_reply.started":"2024-05-25T08:38:39.031222Z","shell.execute_reply":"2024-05-25T08:38:39.037242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dataset, training_example, batch_size=10, epochs=5, learning_rate=0.01,model_name = \"model\"):\n  \"\"\"\n  This function implements the training logic\n  Inputs:\n  - model: the model ot be trained\n  - train_dataset: the training set of type Dataset\n  - batch_size: integer represents the number of examples per step\n  - epochs: integer represents the total number of epochs (full training pass)\n  - learning_rate: the learning rate to be used by the optimizer\n  \"\"\"\n  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n  criterion = nn.CrossEntropyLoss()\n  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n  # GPU configuration\n  use_cuda = torch.cuda.is_available()\n  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n  if use_cuda:\n    model = model.cuda()\n    criterion = criterion.cuda()\n\n  for epoch_num in range(epochs):\n    total_acc_train = 0\n    total_loss_train = 0\n\n    for source, targets in tqdm(train_dataloader):\n      source = source.transpose(0,1)\n      targets = targets.transpose(0,1)\n      source = source.to(device)\n      targets = targets.to(device)\n      # print(source.shape)\n      # print(targets.shape)\n      output = model(source,targets)\n      # print(\"Output of Seq2seq \", output.shape)\n      output = output[1:].reshape(-1, output.shape[2]) # to neglect start token\n      # print(\"Output of Seq2seq after reshaping \", output.shape)\n      # print(\"target shape \", targets.shape)\n      targets = targets[1:].reshape(-1) # to neglect start token\n      # print(\"target shape after reshaping \", targets.shape)\n\n      batch_loss = criterion(output, targets)\n      total_loss_train += batch_loss.item()\n      # print(\"shape of argmax \", output.argmax(dim=1).shape)\n      acc = (output.argmax(dim=1) == targets).sum().item()\n      total_acc_train += acc\n\n      optimizer.zero_grad()\n      batch_loss.backward()\n      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n      optimizer.step()\n\n    epoch_loss = total_loss_train / len(train_dataset)\n    epoch_acc = total_acc_train / (len(train_dataset) * len(train_dataset[0][0]))\n    print(\n        f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n        | Train Accuracy: {epoch_acc}\\n')\n    print(\"sentence evaluation\",eval_fun(training_example,model))\n    \n  torch.save({\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict()\n}, model_name + '_checkpoint.pth')  ","metadata":{"id":"OXxaRRiXq-oP","executionInfo":{"status":"ok","timestamp":1716379614691,"user_tz":-180,"elapsed":266,"user":{"displayName":"Hossam Gadallah","userId":"16288089119131572369"}},"execution":{"iopub.status.busy":"2024-05-25T08:39:12.421768Z","iopub.execute_input":"2024-05-25T08:39:12.422472Z","iopub.status.idle":"2024-05-25T08:39:12.435544Z","shell.execute_reply.started":"2024-05-25T08:39:12.422438Z","shell.execute_reply":"2024-05-25T08:39:12.434597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test =  ['<SOS>', 'الشي', 'عن', 'برزة', 'وانا', 'ببرزة', '<EOS>']","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:42:26.802362Z","iopub.execute_input":"2024-05-25T12:42:26.802745Z","iopub.status.idle":"2024-05-25T12:42:26.807565Z","shell.execute_reply.started":"2024-05-25T12:42:26.802714Z","shell.execute_reply":"2024-05-25T12:42:26.806470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_to_index['<SOS>']\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T08:39:24.572403Z","iopub.execute_input":"2024-05-25T08:39:24.572761Z","iopub.status.idle":"2024-05-25T08:39:24.578869Z","shell.execute_reply.started":"2024-05-25T08:39:24.572732Z","shell.execute_reply":"2024-05-25T08:39:24.577888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model,dataset,test,batch_size,num_epochs,learning_rate)","metadata":{"id":"mEZCLeVGsJrG","outputId":"13219d26-30c5-412f-fba2-4809f7530df8","execution":{"iopub.status.busy":"2024-05-25T08:39:27.812158Z","iopub.execute_input":"2024-05-25T08:39:27.812802Z","iopub.status.idle":"2024-05-25T12:13:15.836080Z","shell.execute_reply.started":"2024-05-25T08:39:27.812769Z","shell.execute_reply":"2024-05-25T12:13:15.835174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model,test_dataset,batch_size):\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n\n    # GPU Configuration\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    if use_cuda:\n        model = model.cuda()\n    total_acc_eval = 0\n    with torch.no_grad():\n        for source, targets in tqdm(test_dataloader):\n            source = source.transpose(0,1)\n            targets = targets.transpose(0,1)\n            # Move the test input to the device\n            source = source.to(device)\n            # Move the test label to the device\n            targets = targets.to(device)\n\n            # Perform the forward pass\n            output = model.inference(source,source.shape[0])\n\n            output = output[1:].reshape(-1, output.shape[2]) \n          \n            targets = targets[1:].reshape(-1) \n\n            # print(\"shape of argmax \", output.argmax(dim=1).shape)\n            acc = (output.argmax(dim=1) == targets).sum().item()\n            total_acc_eval += acc\n     \n    \n    acc = total_acc_eval / (len(test_dataset) * len(test_dataset[0][0]))\n    print(f'Evaluation Accuracy: {acc}')\n","metadata":{"id":"ITuTNaqhQa2-","executionInfo":{"status":"ok","timestamp":1716320943092,"user_tz":-180,"elapsed":1525,"user":{"displayName":"Hossam Nabil","userId":"15773122680535247840"}},"outputId":"feebc0be-5822-4c50-9879-83f57fdd8b85","execution":{"iopub.status.busy":"2024-05-25T12:14:31.014715Z","iopub.execute_input":"2024-05-25T12:14:31.015679Z","iopub.status.idle":"2024-05-25T12:14:31.025238Z","shell.execute_reply.started":"2024-05-25T12:14:31.015643Z","shell.execute_reply":"2024-05-25T12:14:31.024308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(eval_fun(test,model))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:42:33.285505Z","iopub.execute_input":"2024-05-25T12:42:33.285967Z","iopub.status.idle":"2024-05-25T12:42:33.308900Z","shell.execute_reply.started":"2024-05-25T12:42:33.285935Z","shell.execute_reply":"2024-05-25T12:42:33.307967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'model.pickle')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:13:48.389274Z","iopub.execute_input":"2024-05-25T12:13:48.389883Z","iopub.status.idle":"2024-05-25T12:13:49.944270Z","shell.execute_reply.started":"2024-05-25T12:13:48.389833Z","shell.execute_reply":"2024-05-25T12:13:49.943478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_source, test_targets = read_alignments(file_path_alignments + 'qalb14/qalb14_train.txt')\ntest_source, test_targets = create_windows(test_source, test_targets, window_size = 5)\n# test_source = convert_to_indicies(test_source, source_to_index)\n# test_targets = convert_to_indicies(test_targets, target_to_index)\nprint(test_source[-4],test_targets[-4])","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:40:02.792525Z","iopub.execute_input":"2024-05-25T12:40:02.792901Z","iopub.status.idle":"2024-05-25T12:40:06.103282Z","shell.execute_reply.started":"2024-05-25T12:40:02.792872Z","shell.execute_reply":"2024-05-25T12:40:06.102353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset(test_source, test_targets)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:32:24.462756Z","iopub.execute_input":"2024-05-25T12:32:24.463225Z","iopub.status.idle":"2024-05-25T12:32:24.475759Z","shell.execute_reply.started":"2024-05-25T12:32:24.463174Z","shell.execute_reply":"2024-05-25T12:32:24.474722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model,test_dataset,batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:32:26.706108Z","iopub.execute_input":"2024-05-25T12:32:26.706479Z","iopub.status.idle":"2024-05-25T12:32:29.368140Z","shell.execute_reply.started":"2024-05-25T12:32:26.706448Z","shell.execute_reply":"2024-05-25T12:32:29.366959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:24:25.224950Z","iopub.execute_input":"2024-05-25T12:24:25.225336Z","iopub.status.idle":"2024-05-25T12:24:25.229874Z","shell.execute_reply.started":"2024-05-25T12:24:25.225302Z","shell.execute_reply":"2024-05-25T12:24:25.228845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink \nFileLink(r'model_checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:25:26.545528Z","iopub.execute_input":"2024-05-25T12:25:26.545910Z","iopub.status.idle":"2024-05-25T12:25:26.552440Z","shell.execute_reply.started":"2024-05-25T12:25:26.545879Z","shell.execute_reply":"2024-05-25T12:25:26.551524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}